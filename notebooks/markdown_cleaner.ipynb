{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "866ea665",
   "metadata": {},
   "source": [
    "# Markdown Cleaner\n",
    "\n",
    "流程分成兩步：\n",
    "1. **Markdown 清理**：讀取來源檔、依設定移除粗體標記／註解、輸出新的 `.md`，同時把內容存入 `processed_text`。\n",
    "2. **Word 匯出（可選）**：執行第二個程式格產生 `.docx`；若 `use_style_template = True` 且 `style_template_relative` 指向樣式檔/資料夾，會套用該樣式，並保留標題層級、第二個 `##` 起換頁。\n",
    "\n",
    "先在「設定區」調整參數，再依序執行「Markdown 清理」與「Word 匯出」。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e80f999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in /opt/conda/lib/python3.11/site-packages (1.2.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from python-docx) (6.0.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /opt/conda/lib/python3.11/site-packages (from python-docx) (4.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e8e0881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# ---- 設定區：可依需求調整 ----\n",
    "source_relative = Path('mkdocs/My_Notes/113憲判字11號判決/法官學院書面稿.md')\n",
    "\n",
    "output_relative = Path('mkdocs/My_Notes/113憲判字11號判決/給老師的/遺產稅案例研討_法官學院書面稿_20251011.md')\n",
    "word_output_relative = Path('mkdocs/My_Notes/113憲判字11號判決/給老師的/遺產稅案例研討_法官學院書面稿_20251011.docx')\n",
    "\n",
    "style_template_relative = Path('mkdocs/My_Notes/113憲判字11號判決/給老師的/word樣式文件夾/我的word樣式檔案')\n",
    "\n",
    "use_style_template = False\n",
    "\n",
    "remove_bold = True\n",
    "remove_comments = True\n",
    "normalize_headings = False\n",
    "export_word = True\n",
    "\n",
    "# --------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "601e1259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "來源檔案：/home/jovyan/work/mkdocs/My_Notes/113憲判字11號判決/法官學院書面稿.md\n",
      "原始字元數：29,752\n",
      "已輸出：/home/jovyan/work/mkdocs/My_Notes/113憲判字11號判決/給老師的/遺產稅案例研討_法官學院書面稿_20251011.md\n",
      "新檔字元數：29,138\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from typing import Optional\n",
    "\n",
    "BASE_DIR = Path.cwd()\n",
    "possible_roots = [BASE_DIR, BASE_DIR / 'work'] + list(BASE_DIR.parents) + list((BASE_DIR / 'work').parents)\n",
    "\n",
    "\n",
    "def resolve_path(relative) -> Optional[Path]:\n",
    "    if relative is None:\n",
    "        return None\n",
    "    p = Path(relative)\n",
    "    if p.is_absolute():\n",
    "        return p if p.exists() else None\n",
    "    for base in possible_roots:\n",
    "        candidate = (Path(base) / p).resolve()\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "    return None\n",
    "\n",
    "source_path = resolve_path(source_relative)\n",
    "if not source_path:\n",
    "    raise FileNotFoundError(f\"找不到來源檔案：{source_relative}\")\n",
    "\n",
    "repo_root = None\n",
    "for parent in source_path.parents:\n",
    "    candidate = parent / 'mkdocs'\n",
    "    if candidate.exists():\n",
    "        repo_root = parent\n",
    "        break\n",
    "if repo_root is None:\n",
    "    for base in possible_roots:\n",
    "        base = Path(base)\n",
    "        if (base / 'mkdocs').exists():\n",
    "            repo_root = base\n",
    "            break\n",
    "if repo_root is None:\n",
    "    repo_root = BASE_DIR\n",
    "\n",
    "if output_relative.is_absolute():\n",
    "    output_path = output_relative\n",
    "else:\n",
    "    output_path = (repo_root / output_relative).resolve()\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "word_output_path = None\n",
    "if export_word and word_output_relative:\n",
    "    if word_output_relative.is_absolute():\n",
    "        word_output_path = word_output_relative\n",
    "    else:\n",
    "        word_output_path = (repo_root / word_output_relative).resolve()\n",
    "    word_output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "style_template_resolved = None\n",
    "if use_style_template and style_template_relative:\n",
    "    candidate = resolve_path(style_template_relative)\n",
    "    if candidate is None:\n",
    "        candidate = Path(style_template_relative)\n",
    "        if candidate.exists():\n",
    "            candidate = candidate.resolve()\n",
    "    style_template_resolved = candidate\n",
    "\n",
    "text = source_path.read_text(encoding='utf-8')\n",
    "print(f\"來源檔案：{source_path}\")\n",
    "print(f\"原始字元數：{len(text):,}\")\n",
    "\n",
    "processed_text = text\n",
    "if remove_bold:\n",
    "    processed_text = re.sub(r\"\\*\\*(.+?)\\*\\*\", lambda m: m.group(1), processed_text, flags=re.DOTALL)\n",
    "    processed_text = re.sub(r\"__(.+?)__\", lambda m: m.group(1), processed_text, flags=re.DOTALL)\n",
    "\n",
    "if remove_comments:\n",
    "    processed_text = re.sub(r\"<!--.*?-->\", \"\", processed_text, flags=re.DOTALL)\n",
    "\n",
    "if normalize_headings:\n",
    "    def normalize(match):\n",
    "        hashes, title = match.group(1), match.group(2).strip()\n",
    "        if len(hashes) <= 1:\n",
    "            return '# ' + title\n",
    "        return '## ' + title\n",
    "    processed_text = re.sub(r\"^(#+)\\s*(.*)$\", normalize, processed_text, flags=re.MULTILINE)\n",
    "\n",
    "output_path.write_text(processed_text, encoding='utf-8')\n",
    "print(f\"已輸出：{output_path}\")\n",
    "print(f\"新檔字元數：{len(processed_text):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfd6fa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已輸出 Word（python-docx）：/home/jovyan/work/mkdocs/My_Notes/113憲判字11號判決/給老師的/遺產稅案例研討_法官學院書面稿_20251011.docx\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import shutil\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Tuple\n",
    "from zipfile import ZipFile\n",
    "\n",
    "try:\n",
    "    from docx import Document\n",
    "    from docx.enum.style import WD_STYLE_TYPE\n",
    "    from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "    from docx.oxml import OxmlElement\n",
    "    from docx.oxml.ns import qn\n",
    "    from docx.shared import Pt, RGBColor\n",
    "except ImportError:\n",
    "    Document = None\n",
    "\n",
    "ALLOWED_TEMPLATE_SUFFIXES = {'.dotx', '.docx'}\n",
    "\n",
    "LIST_ITEM_RE = re.compile(r'^(?P<indent>[ \t]*)(?P<marker>(?:[*+-])|(?:\\d+[.)]))\\s+(?P<content>.*)$')\n",
    "TABLE_DIVIDER_RE = re.compile(r'^\\s*\\|?\\s*:?-{3,}:?\\s*(?:\\|\\s*:?-{3,}:?\\s*)*\\|?\\s*$')\n",
    "TABLE_ROW_SPLIT_RE = re.compile(r'(?<!\\\\)\\|')\n",
    "\n",
    "def _indent_width(text: str) -> int:\n",
    "    width = 0\n",
    "    for char in text:\n",
    "        width += 4 if char == '\t' else 1\n",
    "    return width\n",
    "\n",
    "def _collapse_content(lines: List[str]) -> str:\n",
    "    paragraphs: List[str] = []\n",
    "    buffer: List[str] = []\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "        if not stripped:\n",
    "            if buffer:\n",
    "                paragraphs.append(' '.join(buffer).strip())\n",
    "                buffer.clear()\n",
    "        else:\n",
    "            buffer.append(stripped)\n",
    "    if buffer:\n",
    "        paragraphs.append(' '.join(buffer).strip())\n",
    "    return '\\n'.join(paragraphs).strip()\n",
    "\n",
    "def _split_table_row(line: str) -> List[str]:\n",
    "    trimmed = line.strip()\n",
    "    if not trimmed:\n",
    "        return []\n",
    "    if trimmed.startswith('|'):\n",
    "        trimmed = trimmed[1:]\n",
    "    if trimmed.endswith('|'):\n",
    "        trimmed = trimmed[:-1]\n",
    "    parts = TABLE_ROW_SPLIT_RE.split(trimmed)\n",
    "    return [part.replace('\\|', '|').strip() for part in parts]\n",
    "\n",
    "def _is_table_divider(line: str) -> bool:\n",
    "    return bool(TABLE_DIVIDER_RE.match(line.strip()))\n",
    "\n",
    "def _is_table_start(lines: List[str], index: int) -> bool:\n",
    "    return index + 1 < len(lines) and '|' in lines[index] and _is_table_divider(lines[index + 1])\n",
    "\n",
    "def _parse_alignment(spec: str) -> str:\n",
    "    spec = spec.strip()\n",
    "    left = spec.startswith(':')\n",
    "    right = spec.endswith(':')\n",
    "    if left and right:\n",
    "        return 'center'\n",
    "    if right:\n",
    "        return 'right'\n",
    "    return 'left'\n",
    "\n",
    "def _normalize_row_length(values: List[str], count: int, fill: str = '') -> List[str]:\n",
    "    result = list(values)\n",
    "    if len(result) < count:\n",
    "        result.extend([fill] * (count - len(result)))\n",
    "    elif len(result) > count:\n",
    "        del result[count:]\n",
    "    return result\n",
    "\n",
    "def _parse_table(lines: List[str], index: int) -> Tuple[dict, int]:\n",
    "    header = _split_table_row(lines[index])\n",
    "    align_specs = _split_table_row(lines[index + 1]) if index + 1 < len(lines) else []\n",
    "    alignments = [_parse_alignment(spec) for spec in align_specs]\n",
    "    rows: List[List[str]] = []\n",
    "    i = index + 2\n",
    "    while i < len(lines):\n",
    "        raw = lines[i]\n",
    "        if not raw.strip():\n",
    "            break\n",
    "        if '|' not in raw:\n",
    "            break\n",
    "        row = _split_table_row(raw)\n",
    "        if not row:\n",
    "            break\n",
    "        rows.append(row)\n",
    "        i += 1\n",
    "    column_count = len(header)\n",
    "    for row in rows:\n",
    "        column_count = max(column_count, len(row))\n",
    "    if column_count == 0 and rows:\n",
    "        column_count = len(rows[0])\n",
    "    if column_count == 0:\n",
    "        column_count = 1\n",
    "    header = _normalize_row_length(header, column_count)\n",
    "    alignments = _normalize_row_length(alignments, column_count, fill='left')\n",
    "    normalized_rows = [_normalize_row_length(row, column_count) for row in rows]\n",
    "    return ({'type': 'table', 'header': header, 'align': alignments, 'rows': normalized_rows}, i)\n",
    "\n",
    "def _parse_paragraph(lines: List[str], start: int) -> Tuple[dict, int]:\n",
    "    collected: List[str] = []\n",
    "    i = start\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        stripped = line.strip()\n",
    "        if not stripped:\n",
    "            break\n",
    "        if _is_table_start(lines, i):\n",
    "            break\n",
    "        if LIST_ITEM_RE.match(line):\n",
    "            break\n",
    "        if stripped.startswith('#'):\n",
    "            break\n",
    "        if stripped == '---':\n",
    "            break\n",
    "        collected.append(line)\n",
    "        i += 1\n",
    "    if not collected and i < len(lines):\n",
    "        collected.append(lines[i])\n",
    "        i += 1\n",
    "    return ({'type': 'paragraph', 'text': _collapse_content(collected)}, i)\n",
    "\n",
    "def _parse_list(lines: List[str], start: int, base_indent: Optional[int] = None) -> Tuple[dict, int]:\n",
    "    items: List[dict] = []\n",
    "    ordered: Optional[bool] = None\n",
    "    i = start\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        match = LIST_ITEM_RE.match(line)\n",
    "        if not match:\n",
    "            if items and line.strip():\n",
    "                indent = _indent_width(line[:len(line) - len(line.lstrip(' '))])\n",
    "                if indent > (base_indent or 0):\n",
    "                    items[-1]['content'].append(line.strip())\n",
    "                    i += 1\n",
    "                    continue\n",
    "            if items and not line.strip():\n",
    "                items[-1]['content'].append('')\n",
    "                i += 1\n",
    "                continue\n",
    "            break\n",
    "        indent = _indent_width(match.group('indent'))\n",
    "        marker = match.group('marker')\n",
    "        content = match.group('content').rstrip()\n",
    "        if base_indent is None:\n",
    "            base_indent = indent\n",
    "        if indent < base_indent:\n",
    "            break\n",
    "        if indent > base_indent:\n",
    "            if not items:\n",
    "                break\n",
    "            nested_block, new_index = _parse_list(lines, i, indent)\n",
    "            items[-1].setdefault('children', []).append(nested_block)\n",
    "            i = new_index\n",
    "            continue\n",
    "        current_ordered = marker[0].isdigit()\n",
    "        if ordered is None:\n",
    "            ordered = current_ordered\n",
    "        elif ordered != current_ordered:\n",
    "            break\n",
    "        items.append({'content': [content], 'children': []})\n",
    "        i += 1\n",
    "        while i < len(lines):\n",
    "            next_line = lines[i]\n",
    "            if not next_line.strip():\n",
    "                items[-1]['content'].append('')\n",
    "                i += 1\n",
    "                continue\n",
    "            next_match = LIST_ITEM_RE.match(next_line)\n",
    "            if next_match:\n",
    "                next_indent = _indent_width(next_match.group('indent'))\n",
    "                if next_indent <= base_indent:\n",
    "                    break\n",
    "                nested_block, new_index = _parse_list(lines, i, next_indent)\n",
    "                items[-1].setdefault('children', []).append(nested_block)\n",
    "                i = new_index\n",
    "                continue\n",
    "            next_indent = _indent_width(next_line[:len(next_line) - len(next_line.lstrip(' '))])\n",
    "            if next_indent > base_indent:\n",
    "                items[-1]['content'].append(next_line.strip())\n",
    "                i += 1\n",
    "                continue\n",
    "            break\n",
    "    normalized_items: List[dict] = []\n",
    "    for item in items:\n",
    "        text = _collapse_content(item['content'])\n",
    "        children = [child for child in item.get('children', []) if child.get('items')]\n",
    "        normalized_items.append({'text': text, 'children': children})\n",
    "    return ({'type': 'list', 'ordered': bool(ordered), 'items': normalized_items}, i)\n",
    "\n",
    "def _parse_markdown_blocks(text: str) -> List[dict]:\n",
    "    lines = text.splitlines()\n",
    "    blocks: List[dict] = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        stripped = line.strip()\n",
    "        if not stripped:\n",
    "            i += 1\n",
    "            continue\n",
    "        if _is_table_start(lines, i):\n",
    "            table_block, i = _parse_table(lines, i)\n",
    "            blocks.append(table_block)\n",
    "            continue\n",
    "        list_match = LIST_ITEM_RE.match(line)\n",
    "        if list_match:\n",
    "            list_block, new_index = _parse_list(lines, i, _indent_width(list_match.group('indent')))\n",
    "            if list_block['items']:\n",
    "                blocks.append(list_block)\n",
    "                i = new_index\n",
    "                continue\n",
    "        if stripped.startswith('#'):\n",
    "            level = len(stripped) - len(stripped.lstrip('#'))\n",
    "            heading_text = stripped[level:].strip()\n",
    "            blocks.append({'type': 'heading', 'level': level, 'text': heading_text})\n",
    "            i += 1\n",
    "            continue\n",
    "        if stripped == '---':\n",
    "            blocks.append({'type': 'horizontal_rule'})\n",
    "            i += 1\n",
    "            continue\n",
    "        paragraph_block, new_index = _parse_paragraph(lines, i)\n",
    "        if paragraph_block['text']:\n",
    "            blocks.append(paragraph_block)\n",
    "        i = max(new_index, i + 1)\n",
    "    return blocks\n",
    "\n",
    "def is_docx_archive(path: Path) -> bool:\n",
    "    try:\n",
    "        with ZipFile(path) as zf:\n",
    "            return 'word/document.xml' in zf.namelist()\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def select_template(path: Optional[Path]) -> Optional[Path]:\n",
    "    if path is None:\n",
    "        return None\n",
    "    candidate = Path(path)\n",
    "    if candidate.is_dir():\n",
    "        dotx_files = sorted(candidate.glob('*.dotx'))\n",
    "        docx_files = sorted(candidate.glob('*.docx'))\n",
    "        candidate = dotx_files[0] if dotx_files else (docx_files[0] if docx_files else None)\n",
    "    elif candidate.suffix.lower() not in ALLOWED_TEMPLATE_SUFFIXES:\n",
    "        dotx_try = candidate.with_suffix('.dotx')\n",
    "        if dotx_try.exists():\n",
    "            candidate = dotx_try\n",
    "        else:\n",
    "            docx_try = candidate.with_suffix('.docx')\n",
    "            if docx_try.exists():\n",
    "                candidate = docx_try\n",
    "            elif candidate.exists() and is_docx_archive(candidate):\n",
    "                return candidate\n",
    "            else:\n",
    "                candidate = None\n",
    "    if candidate and candidate.exists():\n",
    "        return candidate\n",
    "    print(f\"⚠️ 找不到樣式集：{path}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def apply_template_styles(doc_path: Path, template_path: Path) -> None:\n",
    "    doc_path = Path(doc_path)\n",
    "    template_path = Path(template_path)\n",
    "    with tempfile.TemporaryDirectory() as tmp_doc, tempfile.TemporaryDirectory() as tmp_tpl:\n",
    "        tmp_doc = Path(tmp_doc)\n",
    "        tmp_tpl = Path(tmp_tpl)\n",
    "        with ZipFile(doc_path, 'r') as zin:\n",
    "            zin.extractall(tmp_doc)\n",
    "        with ZipFile(template_path, 'r') as zin:\n",
    "            zin.extractall(tmp_tpl)\n",
    "        for rel in ['word/styles.xml', 'word/numbering.xml', 'word/theme/theme1.xml']:\n",
    "            src = tmp_tpl / rel\n",
    "            if src.exists():\n",
    "                dst = tmp_doc / rel\n",
    "                dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "                shutil.copy(src, dst)\n",
    "        tmp_output = doc_path.with_suffix('.tmp.docx')\n",
    "        with ZipFile(tmp_output, 'w') as zout:\n",
    "            for file in tmp_doc.rglob('*'):\n",
    "                if file.is_file():\n",
    "                    zout.write(file, file.relative_to(tmp_doc))\n",
    "        tmp_output.replace(doc_path)\n",
    "\n",
    "\n",
    "def export_to_docx(processed: str, destination: Path, template_path: Optional[Path]) -> None:\n",
    "    if Document is None:\n",
    "        print('⚠️ 未安裝 python-docx，無法輸出 Word。請執行 `pip install python-docx` 後重試。')\n",
    "        return\n",
    "    dest_path = Path(destination)\n",
    "    dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    template = select_template(template_path) if use_style_template else None\n",
    "    temp_template: Optional[Path] = None\n",
    "    try:\n",
    "        if template and template.suffix.lower() not in ALLOWED_TEMPLATE_SUFFIXES and template.exists():\n",
    "            temp_template = dest_path.with_suffix('.template.dotx')\n",
    "            shutil.copyfile(template, temp_template)\n",
    "            template = temp_template\n",
    "        if template and template.exists():\n",
    "            document = Document(str(template))\n",
    "            body = document._element.body\n",
    "            for child in list(body):\n",
    "                body.remove(child)\n",
    "        else:\n",
    "            document = Document()\n",
    "        target_styles = {'Normal', 'Heading 1', 'Heading 2', 'Heading 3', 'Heading 4', 'Heading 5', 'Heading 6'}\n",
    "        if document.styles:\n",
    "            for style in document.styles:\n",
    "                if style.type == WD_STYLE_TYPE.PARAGRAPH and style.name in target_styles:\n",
    "                    style.font.color.rgb = RGBColor(0, 0, 0)\n",
    "                    style.paragraph_format.left_indent = None\n",
    "                    style.paragraph_format.first_line_indent = None\n",
    "        blocks = _parse_markdown_blocks(processed)\n",
    "        heading2_seen = False\n",
    "        alignment_map = {\n",
    "            'left': WD_ALIGN_PARAGRAPH.LEFT,\n",
    "            'center': WD_ALIGN_PARAGRAPH.CENTER,\n",
    "            'right': WD_ALIGN_PARAGRAPH.RIGHT,\n",
    "        }\n",
    "\n",
    "        def _set_runs_black(paragraph) -> None:\n",
    "            for run in paragraph.runs:\n",
    "                run.font.color.rgb = RGBColor(0, 0, 0)\n",
    "\n",
    "        def _write_text(paragraph, content: str, bold: bool = False) -> None:\n",
    "            for run in paragraph.runs[::-1]:\n",
    "                paragraph._p.remove(run._element)\n",
    "            if not content:\n",
    "                run = paragraph.add_run(' ')\n",
    "                if bold:\n",
    "                    run.font.bold = True\n",
    "            else:\n",
    "                parts = content.split('\\n')\n",
    "                for idx, part in enumerate(parts):\n",
    "                    if idx:\n",
    "                        paragraph.add_run().add_break()\n",
    "                    run = paragraph.add_run(part)\n",
    "                    if bold:\n",
    "                        run.font.bold = True\n",
    "            _set_runs_black(paragraph)\n",
    "\n",
    "        def _find_style_name(candidates: List[str], expected_type) -> Optional[str]:\n",
    "            for name in candidates:\n",
    "                try:\n",
    "                    style = document.styles[name]\n",
    "                except KeyError:\n",
    "                    continue\n",
    "                if style.type == expected_type:\n",
    "                    return name\n",
    "            return None\n",
    "\n",
    "        bullet_style = _find_style_name(['List Bullet', 'Bulleted List', 'List Paragraph'], WD_STYLE_TYPE.PARAGRAPH)\n",
    "        number_style = _find_style_name(['List Number', 'Numbered List', 'List Paragraph'], WD_STYLE_TYPE.PARAGRAPH)\n",
    "        table_style_name = _find_style_name(['Table Grid', 'Table Normal', 'Light Grid'], WD_STYLE_TYPE.TABLE)\n",
    "\n",
    "        def render_list(block: dict, level: int = 0) -> None:\n",
    "            style_name = number_style if block.get('ordered') else bullet_style\n",
    "            for item in block.get('items', []):\n",
    "                text = item.get('text', '')\n",
    "                para = document.add_paragraph(style=style_name) if style_name else document.add_paragraph()\n",
    "                para.paragraph_format.first_line_indent = None\n",
    "                if level:\n",
    "                    para.paragraph_format.left_indent = Pt(18 * level)\n",
    "                _write_text(para, text)\n",
    "                for child in item.get('children', []):\n",
    "                    if child.get('type') == 'list':\n",
    "                        render_list(child, level + 1)\n",
    "\n",
    "        def render_table(block: dict) -> None:\n",
    "            header = block.get('header', [])\n",
    "            rows = block.get('rows', [])\n",
    "            alignments = block.get('align', [])\n",
    "            columns = len(header) if header else (len(rows[0]) if rows else 0)\n",
    "            if columns == 0:\n",
    "                return\n",
    "            total_rows = len(rows) + (1 if header else 0)\n",
    "            if total_rows == 0:\n",
    "                return\n",
    "            table = document.add_table(rows=total_rows, cols=columns)\n",
    "            if table_style_name:\n",
    "                table.style = table_style_name\n",
    "            current_row = 0\n",
    "            if header:\n",
    "                for col_idx in range(columns):\n",
    "                    cell = table.cell(0, col_idx)\n",
    "                    paragraph = cell.paragraphs[0]\n",
    "                    alignment_key = alignments[col_idx] if col_idx < len(alignments) else 'left'\n",
    "                    paragraph.paragraph_format.alignment = alignment_map.get(alignment_key, WD_ALIGN_PARAGRAPH.LEFT)\n",
    "                    _write_text(paragraph, header[col_idx] if col_idx < len(header) else '', bold=True)\n",
    "                current_row = 1\n",
    "            for row_idx, data in enumerate(rows):\n",
    "                table_row = table.rows[current_row + row_idx]\n",
    "                for col_idx in range(columns):\n",
    "                    cell = table_row.cells[col_idx]\n",
    "                    paragraph = cell.paragraphs[0]\n",
    "                    alignment_key = alignments[col_idx] if col_idx < len(alignments) else 'left'\n",
    "                    paragraph.paragraph_format.alignment = alignment_map.get(alignment_key, WD_ALIGN_PARAGRAPH.LEFT)\n",
    "                    cell_text = data[col_idx] if col_idx < len(data) else ''\n",
    "                    _write_text(paragraph, cell_text)\n",
    "\n",
    "        for block in blocks:\n",
    "            block_type = block.get('type')\n",
    "            if block_type == 'horizontal_rule':\n",
    "                para = document.add_paragraph('')\n",
    "                p = para._p\n",
    "                pPr = p.get_or_add_pPr()\n",
    "                pBdr = OxmlElement('w:pBdr')\n",
    "                bottom = OxmlElement('w:bottom')\n",
    "                bottom.set(qn('w:val'), 'single')\n",
    "                bottom.set(qn('w:sz'), '6')\n",
    "                bottom.set(qn('w:space'), '1')\n",
    "                bottom.set(qn('w:color'), '000000')\n",
    "                pBdr.append(bottom)\n",
    "                pPr.append(pBdr)\n",
    "            elif block_type == 'heading':\n",
    "                level = block.get('level', 1)\n",
    "                doc_level = max(1, min(level, 9))\n",
    "                if doc_level == 2:\n",
    "                    if heading2_seen:\n",
    "                        document.add_page_break()\n",
    "                    heading2_seen = True\n",
    "                para = document.add_heading(block.get('text') or ' ', level=doc_level)\n",
    "                _set_runs_black(para)\n",
    "            elif block_type == 'list':\n",
    "                if block.get('items'):\n",
    "                    render_list(block, 0)\n",
    "            elif block_type == 'table':\n",
    "                render_table(block)\n",
    "            elif block_type == 'paragraph':\n",
    "                text = block.get('text', '').strip()\n",
    "                if text:\n",
    "                    para = document.add_paragraph()\n",
    "                    _write_text(para, text)\n",
    "\n",
    "        document.save(dest_path)\n",
    "        if template and template.exists():\n",
    "            apply_template_styles(dest_path, template)\n",
    "        print(f\"已輸出 Word（python-docx）：{dest_path}\")\n",
    "    except Exception as err:\n",
    "        print(f'⚠️ Word 匯出失敗：{err}')\n",
    "        if dest_path.exists():\n",
    "            dest_path.unlink(missing_ok=True)\n",
    "    finally:\n",
    "        if temp_template and temp_template.exists():\n",
    "            temp_template.unlink(missing_ok=True)\n",
    "\n",
    "if not export_word:\n",
    "    print('Word 匯出已停用，未產生 .docx。')\n",
    "elif word_output_path is None:\n",
    "    print('⚠️ 未設定 word_output_relative，因此略過 Word 匯出。')\n",
    "elif 'processed_text' not in globals():\n",
    "    print('⚠️ 找不到 processed_text，請先執行 Markdown 清理程式格。')\n",
    "else:\n",
    "    export_to_docx(processed_text, word_output_path, style_template_resolved)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
