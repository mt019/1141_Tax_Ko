{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3217a55e",
   "metadata": {},
   "source": [
    "# 租稅法總論稿件合併\n",
    "\n",
    "這個 notebook 會將 `_Material/1121稿/Filtered_租稅法總論` 中的逐次講義整合成單一的 Word 檔案，並依據每份檔案的 YAML 前言建立段落標題。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e585b88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 如環境尚未安裝相關套件，可以先執行這個區塊。\n",
    "%pip install -q python-docx pyyaml\n",
    "# %pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17903889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory : /Users/iw/Documents/NTU/1141/1141_Tax_Ko/notebooks\n",
      "使用資料夾        : mkdocs/My_Notes/課_二89_租稅法總論\n",
      "Source directory  : /Users/iw/Documents/NTU/1141/1141_Tax_Ko/mkdocs/My_Notes/課_二89_租稅法總論\n",
      "Word template     : mkdocs/My_Notes/word樣式文件夾/Doc1.dotx\n",
      "Output file       : /Users/iw/Documents/NTU/1141/1141_Tax_Ko/mkdocs/My_Notes/課_二89_租稅法總論/課_二89_租稅法總論_合併測試.docx\n",
      "Auto TOC enabled  : True\n",
      "East Asia font    : None\n",
      "Auto field update : True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "# === 基本環境設定 ===\n",
    "BASE_DIR = Path.cwd().resolve()\n",
    "\n",
    "\n",
    "def build_possible_roots(*paths: Path) -> List[Path]:\n",
    "    roots: List[Path] = []\n",
    "    for path in paths:\n",
    "        if path is None:\n",
    "            continue\n",
    "        path = path.expanduser()\n",
    "        for candidate in [path] + list(path.parents):\n",
    "            candidate = candidate.resolve()\n",
    "            if candidate not in roots:\n",
    "                roots.append(candidate)\n",
    "    return roots\n",
    "\n",
    "\n",
    "possible_roots = build_possible_roots(BASE_DIR, BASE_DIR / 'work')\n",
    "\n",
    "\n",
    "def ensure_path(value: Union[Path, str, None]) -> Optional[Path]:\n",
    "    if value is None or value == \"\":\n",
    "        return None\n",
    "    if isinstance(value, Path):\n",
    "        return value\n",
    "    return Path(value)\n",
    "\n",
    "\n",
    "def resolve_existing(target: Union[Path, str, None]) -> Optional[Path]:\n",
    "    candidate = ensure_path(target)\n",
    "    if candidate is None:\n",
    "        return None\n",
    "    candidate = candidate.expanduser()\n",
    "    if candidate.is_absolute():\n",
    "        resolved = candidate.resolve()\n",
    "        return resolved if resolved.exists() else None\n",
    "    for base in possible_roots:\n",
    "        resolved = (base / candidate).resolve()\n",
    "        if resolved.exists():\n",
    "            return resolved\n",
    "    return None\n",
    "\n",
    "\n",
    "# === 使用者可調整參數 ===\n",
    "CONFIG_INPUT_PATH: Union[Path, str, None] = None  # 指定來源資料夾（可為相對或絕對路徑）\n",
    "CONFIG_OUTPUT_PATH: Union[Path, str, None] = None  # 指定輸出檔案名稱或路徑\n",
    "OUTPUT_SUFFIX = '_合併測試.docx'\n",
    "WORD_TEMPLATE_PATH: Union[Path, str, None] = Path('mkdocs/My_Notes/word樣式文件夾/Doc1.dotx')\n",
    "EAST_ASIA_FONT_OVERRIDE: Optional[str] = None  # None 表示沿用模板字體\n",
    "AUTO_INSERT_TOC = True\n",
    "TOC_TITLE = '目錄'\n",
    "TOC_MAX_LEVEL = 6  # 指定自動目錄包含的最大標題層級，預設為 4\n",
    "TOC_LEVEL_RANGE = f'1-{TOC_MAX_LEVEL}'\n",
    "TOC_HEADING_LEVEL = 1\n",
    "TOC_PAGE_BREAK_AFTER = True\n",
    "AUTO_UPDATE_WORD_FIELDS = True\n",
    "\n",
    "\n",
    "SOURCE_CANDIDATES = [\n",
    "    Path('mkdocs/My_Notes/課_二89_租稅法總論'),\n",
    "    # Path('mkdocs/My_Notes/_1121_租稅法總論'),\n",
    "]\n",
    "\n",
    "\n",
    "# \n",
    "\n",
    "SOURCE_RELATIVE = None\n",
    "SOURCE_DIR = None\n",
    "\n",
    "preferred_input = resolve_existing(CONFIG_INPUT_PATH)\n",
    "if preferred_input is not None:\n",
    "    SOURCE_RELATIVE = ensure_path(CONFIG_INPUT_PATH)\n",
    "    SOURCE_DIR = preferred_input\n",
    "else:\n",
    "    for candidate in SOURCE_CANDIDATES:\n",
    "        resolved = resolve_existing(candidate)\n",
    "        if resolved is not None:\n",
    "            SOURCE_RELATIVE = candidate\n",
    "            SOURCE_DIR = resolved\n",
    "            break\n",
    "\n",
    "if SOURCE_DIR is None:\n",
    "    joined = \" - \".join(str(c) for c in SOURCE_CANDIDATES)\n",
    "    raise FileNotFoundError('找不到講義資料夾，已嘗試: - ' + joined)\n",
    "\n",
    "\n",
    "TEMPLATE_RELATIVE: Optional[Path] = None\n",
    "TEMPLATE_PATH: Optional[Path] = None\n",
    "if WORD_TEMPLATE_PATH is not None:\n",
    "    template_resolved = resolve_existing(WORD_TEMPLATE_PATH)\n",
    "    if template_resolved is None:\n",
    "        raise FileNotFoundError(f\"找不到 Word 範本：{WORD_TEMPLATE_PATH}\")\n",
    "    TEMPLATE_RELATIVE = ensure_path(WORD_TEMPLATE_PATH)\n",
    "    TEMPLATE_PATH = template_resolved\n",
    "\n",
    "\n",
    "OUTPUT_PATH = None\n",
    "\n",
    "def derive_output_path(source_dir: Path, override: Union[Path, str, None] = None, suffix: str = OUTPUT_SUFFIX) -> Path:\n",
    "    override_path = ensure_path(override)\n",
    "    if override_path is not None:\n",
    "        override_path = override_path.expanduser()\n",
    "        if not override_path.suffix:\n",
    "            override_path = override_path.with_suffix('.docx')\n",
    "        if override_path.is_absolute():\n",
    "            return override_path.resolve()\n",
    "        return (source_dir / override_path).resolve()\n",
    "\n",
    "    base_name = source_dir.name or '合併'\n",
    "    if base_name.startswith('Filtered_'):\n",
    "        base_name = base_name[len('Filtered_'):]\n",
    "    file_name = f'{base_name}{suffix}'\n",
    "    if not file_name.lower().endswith('.docx'):\n",
    "        file_name = f'{file_name}.docx'\n",
    "    return (source_dir / file_name).resolve()\n",
    "\n",
    "\n",
    "OUTPUT_PATH = derive_output_path(SOURCE_DIR, CONFIG_OUTPUT_PATH)\n",
    "\n",
    "print(f'Working directory : {BASE_DIR}')\n",
    "print(f'使用資料夾        : {SOURCE_RELATIVE}')\n",
    "print(f'Source directory  : {SOURCE_DIR}')\n",
    "print(f'Word template     : {TEMPLATE_RELATIVE}')\n",
    "print(f'Output file       : {OUTPUT_PATH}')\n",
    "print(f'Auto TOC enabled  : {AUTO_INSERT_TOC}')\n",
    "print(f'East Asia font    : {EAST_ASIA_FONT_OVERRIDE}')\n",
    "print(f'Auto field update : {AUTO_UPDATE_WORD_FIELDS}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c350256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已輸出 Word（pandoc）：/Users/iw/Documents/NTU/1141/1141_Tax_Ko/mkdocs/My_Notes/課_二89_租稅法總論/課_二89_租稅法總論_合併測試.docx\n",
      "已透過 Word 更新欄位。\n",
      "完成：/Users/iw/Documents/NTU/1141/1141_Tax_Ko/mkdocs/My_Notes/課_二89_租稅法總論/課_二89_租稅法總論_合併測試.docx\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional\n",
    "import sys\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import tempfile\n",
    "import importlib\n",
    "import inspect\n",
    "\n",
    "from docx import Document\n",
    "\n",
    "import importlib.util\n",
    "\n",
    "EAST_ASIA_FONT_OVERRIDE = globals().get('EAST_ASIA_FONT_OVERRIDE', None)\n",
    "\n",
    "# 確保容器內可匯入 notebooks/lib 或 lib 模組\n",
    "for _search_root in [Path.cwd()] + list(Path.cwd().parents):\n",
    "    for _package_root in {_search_root, _search_root / 'notebooks'}:\n",
    "        if _package_root.is_dir() and str(_package_root) not in sys.path:\n",
    "            sys.path.insert(0, str(_package_root))\n",
    "\n",
    "\n",
    "def _import_word_module_from(path: Path):\n",
    "    spec = importlib.util.spec_from_file_location('word_doc_pipeline', path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    assert spec.loader is not None\n",
    "    spec.loader.exec_module(module)\n",
    "    return module\n",
    "\n",
    "\n",
    "def _load_word_pipeline_module():\n",
    "    roots = [Path.cwd()] + list(Path.cwd().parents)\n",
    "    candidate_paths = [\n",
    "        Path('lib/word_doc_pipeline.py'),\n",
    "        Path('notebooks/lib/word_doc_pipeline.py'),\n",
    "        Path('scripts/word_doc_pipeline.py'),\n",
    "    ]\n",
    "\n",
    "    for root in roots:\n",
    "        for rel in candidate_paths:\n",
    "            candidate = (root / rel).resolve()\n",
    "            if candidate.is_file():\n",
    "                return _import_word_module_from(candidate)\n",
    "\n",
    "    for root in roots:\n",
    "        for match in root.rglob('word_doc_pipeline.py'):\n",
    "            return _import_word_module_from(match)\n",
    "\n",
    "    raise ModuleNotFoundError(\n",
    "        \"找不到 word_doc_pipeline.py，請確認 notebooks/lib 或 scripts 目錄存在並已掛載。\"\n",
    "    )\n",
    "\n",
    "\n",
    "MODULE_CANDIDATES = [\n",
    "    'notebooks.lib.word_doc_pipeline',\n",
    "    'lib.word_doc_pipeline',\n",
    "    'scripts.word_doc_pipeline',\n",
    "]\n",
    "\n",
    "_loaded_module = None\n",
    "for module_name in MODULE_CANDIDATES:\n",
    "    try:\n",
    "        module = __import__(module_name, fromlist=['insert_table_of_contents'])\n",
    "        _loaded_module = importlib.reload(module)\n",
    "        break\n",
    "    except ModuleNotFoundError:\n",
    "        continue\n",
    "\n",
    "if _loaded_module is None:\n",
    "    _loaded_module = _load_word_pipeline_module()\n",
    "\n",
    "_loaded_module.DEFAULT_EAST_ASIA_FONT = EAST_ASIA_FONT_OVERRIDE\n",
    "insert_table_of_contents = _loaded_module.insert_table_of_contents\n",
    "update_docx_fields_with_word = _loaded_module.update_docx_fields_with_word\n",
    "DEFAULT_EAST_ASIA_FONT = _loaded_module.DEFAULT_EAST_ASIA_FONT\n",
    "\n",
    "\n",
    "def get_east_asia_font_override() -> Optional[str]:\n",
    "    value = globals().get('EAST_ASIA_FONT_OVERRIDE', DEFAULT_EAST_ASIA_FONT)\n",
    "    if value == \"\" or value is False:\n",
    "        value = None\n",
    "    _loaded_module.DEFAULT_EAST_ASIA_FONT = value\n",
    "    return value\n",
    "\n",
    "\n",
    "# === 全域設定 ===\n",
    "DEFAULT_EAST_ASIA_FONT = '標楷體'\n",
    "PREFERRED_METADATA_KEYS = ['課程', '日期', '周次', '節次']\n",
    "SUPPORTED_EXTENSIONS = ('.md',)\n",
    "HEADING_PATTERN = re.compile(r'^(#{1,6})\\s+(.*)$')\n",
    "CODE_FENCE_PATTERN = re.compile(r'^(```+|~~~+)')\n",
    "SHOW_METADATA_AFTER_HEADING = False\n",
    "TOC_PLACEHOLDER = '[[DOCX_TOC_PLACEHOLDER]]'\n",
    "COMPILED_TITLE = '租稅法總論講義彙編'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Entry:\n",
    "    path: Path\n",
    "    meta: Dict[str, str]\n",
    "    content: str\n",
    "\n",
    "\n",
    "def parse_front_matter(raw_text: str) -> tuple[Dict[str, str], str]:\n",
    "    \"\"\"解析 Markdown front matter，並排除含「課程」欄位。\"\"\"\n",
    "    raw_text = raw_text.lstrip('\\ufeff')\n",
    "    match = re.match(r'^---\\s*\\n(.*?)\\n---\\s*\\n?', raw_text, flags=re.DOTALL)\n",
    "    if not match:\n",
    "        return {}, raw_text.strip()\n",
    "\n",
    "    meta_block = match.group(1)\n",
    "    meta: Dict[str, str] = {}\n",
    "    for line in meta_block.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith('#'):\n",
    "            continue\n",
    "        line = line.replace('：', ':', 1)\n",
    "        if ':' not in line:\n",
    "            continue\n",
    "        key, value = line.split(':', 1)\n",
    "        key = key.strip().replace(':', '').replace('：', '')\n",
    "        if '課程' in key:\n",
    "            continue\n",
    "        meta[key] = value.strip()\n",
    "\n",
    "    body = raw_text[match.end():].lstrip('\\r\\n')\n",
    "    return meta, body.strip()\n",
    "\n",
    "\n",
    "def build_heading(metadata: Dict[str, str], fallback_label: str) -> str:\n",
    "    \"\"\"生成講次小標（metadata 已預先移除含課程欄位）。\"\"\"\n",
    "    if not metadata:\n",
    "        return fallback_label\n",
    "\n",
    "    parts: List[str] = []\n",
    "    if metadata.get('周次'):\n",
    "        w = str(metadata['周次'])\n",
    "        parts.append(f\"第{w}週\" if not w.startswith('第') else w)\n",
    "    if metadata.get('節次'):\n",
    "        s = str(metadata['節次'])\n",
    "        parts.append(f\"第{s}節\" if not s.startswith('第') else s)\n",
    "    if metadata.get('日期'):\n",
    "        parts.append(str(metadata['日期']))\n",
    "\n",
    "    if not parts:\n",
    "        extras = [str(v).strip() for v in metadata.values() if v and str(v).strip()]\n",
    "        return '｜'.join(extras) if extras else fallback_label\n",
    "    return '｜'.join(parts)\n",
    "\n",
    "\n",
    "def collect_entries(source_dir: Path) -> List[Entry]:\n",
    "    if not source_dir.exists():\n",
    "        raise FileNotFoundError(f'找不到資料夾: {source_dir}')\n",
    "\n",
    "    files = sorted([p for ext in SUPPORTED_EXTENSIONS for p in source_dir.glob(f'*{ext}')])\n",
    "    if not files:\n",
    "        raise RuntimeError('資料夾中沒有找到任何支援的檔案 (.md)')\n",
    "\n",
    "    entries: List[Entry] = []\n",
    "    for path in files:\n",
    "        raw = path.read_text(encoding='utf-8')\n",
    "        meta, body = parse_front_matter(raw)\n",
    "        entries.append(Entry(path=path, meta=meta or {}, content=body))\n",
    "    return entries\n",
    "\n",
    "\n",
    "def format_metadata(metadata: Dict[str, str]) -> str:\n",
    "    metadata = {\n",
    "        k: v\n",
    "        for k, v in metadata.items()\n",
    "        if '課程' not in str(k).replace('：', '').replace(':', '').strip()\n",
    "    }\n",
    "    if not metadata:\n",
    "        return ''\n",
    "\n",
    "    items: List[tuple[str, str]] = []\n",
    "    for key in PREFERRED_METADATA_KEYS:\n",
    "        if key in metadata:\n",
    "            items.append((key, metadata[key]))\n",
    "    for key, value in metadata.items():\n",
    "        if key in PREFERRED_METADATA_KEYS:\n",
    "            continue\n",
    "        items.append((key, value))\n",
    "\n",
    "    return '\\n'.join(f'- **{key}**：{value}' for key, value in items)\n",
    "\n",
    "\n",
    "def shift_heading_levels(markdown: str, offset: int = 2) -> str:\n",
    "    if offset == 0:\n",
    "        return markdown\n",
    "\n",
    "    lines = markdown.splitlines()\n",
    "    adjusted: List[str] = []\n",
    "    in_code_block = False\n",
    "\n",
    "    for line in lines:\n",
    "        fence = CODE_FENCE_PATTERN.match(line)\n",
    "        if fence:\n",
    "            in_code_block = not in_code_block\n",
    "            adjusted.append(line)\n",
    "            continue\n",
    "        if in_code_block:\n",
    "            adjusted.append(line)\n",
    "            continue\n",
    "\n",
    "        match = HEADING_PATTERN.match(line)\n",
    "        if not match:\n",
    "            adjusted.append(line)\n",
    "            continue\n",
    "\n",
    "        hashes, title = match.group(1), match.group(2).strip()\n",
    "        current_level = len(hashes)\n",
    "        new_level = min(current_level + offset, 6)\n",
    "        adjusted.append('#' * new_level + ' ' + title)\n",
    "    return '\\n'.join(adjusted)\n",
    "\n",
    "\n",
    "def assemble_markdown(entries: List[Entry]) -> str:\n",
    "    parts: List[str] = [f'# {COMPILED_TITLE}', '']\n",
    "\n",
    "    if AUTO_INSERT_TOC:\n",
    "        parts.append(TOC_PLACEHOLDER)\n",
    "        parts.append('')\n",
    "    else:\n",
    "        parts.extend(['\\\\newpage', ''])\n",
    "\n",
    "    for index, entry in enumerate(entries):\n",
    "        heading = build_heading(entry.meta, entry.path.stem)\n",
    "        parts.append(f'## {heading}')\n",
    "        parts.append('')\n",
    "\n",
    "        if SHOW_METADATA_AFTER_HEADING:\n",
    "            metadata_block = format_metadata(entry.meta)\n",
    "            if metadata_block:\n",
    "                parts.append(metadata_block)\n",
    "                parts.append('')\n",
    "\n",
    "        if entry.content:\n",
    "            parts.append(shift_heading_levels(entry.content, offset=2))\n",
    "\n",
    "        if index != len(entries) - 1:\n",
    "            parts.extend(['', '\\\\newpage', ''])\n",
    "\n",
    "    markdown_output = '\\n'.join(parts)\n",
    "    return markdown_output.strip() + '\\n'\n",
    "\n",
    "\n",
    "def render_markdown_to_docx(markdown_text: str, destination: Path, template_path: Optional[Path]) -> None:\n",
    "    if shutil.which('pandoc') is None:\n",
    "        raise RuntimeError('pandoc 未安裝')\n",
    "\n",
    "    destination.parent.mkdir(parents=True, exist_ok=True)\n",
    "    cleaned = re.sub(r'[ \\t]{2,}$', '', markdown_text, flags=re.MULTILINE)\n",
    "\n",
    "    with tempfile.NamedTemporaryFile('w', suffix='.md', encoding='utf-8', delete=False) as tmp:\n",
    "        tmp.write(cleaned)\n",
    "        tmp_path = tmp.name\n",
    "    try:\n",
    "        cmd = [\n",
    "            'pandoc', tmp_path,\n",
    "            '-f', 'markdown+pipe_tables+lists_without_preceding_blankline+hard_line_breaks+raw_tex+yaml_metadata_block',\n",
    "            '-t', 'docx',\n",
    "            '-o', str(destination),\n",
    "            '--wrap=none',\n",
    "        ]\n",
    "        if template_path:\n",
    "            cmd.extend(['--reference-doc', str(template_path)])\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        if result.returncode != 0:\n",
    "            print('⚠️ Pandoc 錯誤訊息：')\n",
    "            print(result.stderr or result.stdout)\n",
    "            raise subprocess.CalledProcessError(result.returncode, cmd, result.stdout, result.stderr)\n",
    "        print(f\"已輸出 Word（pandoc）：{destination}\")\n",
    "    finally:\n",
    "        Path(tmp_path).unlink(missing_ok=True)\n",
    "\n",
    "\n",
    "def finalize_docx(docx_path: Path, *, auto_update: bool) -> None:\n",
    "    doc = Document(docx_path)\n",
    "    placeholders = [para for para in doc.paragraphs if para.text.strip() == TOC_PLACEHOLDER]\n",
    "\n",
    "    font_choice = get_east_asia_font_override()\n",
    "    if AUTO_INSERT_TOC:\n",
    "        target_para = placeholders[0] if placeholders else None\n",
    "        if target_para is None:\n",
    "            target_para = doc.paragraphs[0] if doc.paragraphs else doc.add_paragraph()\n",
    "        toc_kwargs = dict(\n",
    "            title=TOC_TITLE,\n",
    "            level_range=TOC_LEVEL_RANGE,\n",
    "            heading_level=TOC_HEADING_LEVEL,\n",
    "            east_asia_font=font_choice,\n",
    "            page_break_after=TOC_PAGE_BREAK_AFTER,\n",
    "        )\n",
    "        signature = inspect.signature(insert_table_of_contents)\n",
    "        if 'target_paragraph' in signature.parameters:\n",
    "            toc_kwargs['target_paragraph'] = target_para\n",
    "        insert_table_of_contents(doc, **toc_kwargs)\n",
    "\n",
    "    for para in placeholders:\n",
    "        p = para._element\n",
    "        parent = p.getparent()\n",
    "        if parent is not None:\n",
    "            parent.remove(p)\n",
    "\n",
    "    doc.save(docx_path)\n",
    "    update_docx_fields_with_word(docx_path, enabled=auto_update)\n",
    "\n",
    "\n",
    "def compile_word_document():\n",
    "    entries = collect_entries(SOURCE_DIR)\n",
    "    markdown_text = assemble_markdown(entries)\n",
    "    render_markdown_to_docx(markdown_text, OUTPUT_PATH, TEMPLATE_PATH)\n",
    "    finalize_docx(OUTPUT_PATH, auto_update=AUTO_UPDATE_WORD_FIELDS)\n",
    "    print(f'完成：{OUTPUT_PATH}')\n",
    "\n",
    "\n",
    "compile_word_document()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
